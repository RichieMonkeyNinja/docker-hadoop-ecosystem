{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5c364c-36ae-4b38-9604-33d7f6777502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os \n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "os.environ['HADOOP_USER_NAME'] = 'root'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"bronze-spark-upload-hdfs\") \\\n",
    "    .config(\"spark.driver.host\", \"spark-notebook\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099154de-fa0c-4bb6-babc-b2af3ed78c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/work/bronze_layer/listings/city=bristol/extraction_date=2025-09-26/listings.parquet', '/home/jovyan/work/bronze_layer/listings/city=edinburgh/extraction_date=2025-09-21/listings.parquet', '/home/jovyan/work/bronze_layer/listings/city=london/extraction_date=2025-09-14/listings.parquet']\n",
      "File: /home/jovyan/work/bronze_layer/listings/city=bristol/extraction_date=2025-09-26/listings.parquet | Columns: 79 | Price Type: string\n",
      "File: /home/jovyan/work/bronze_layer/listings/city=edinburgh/extraction_date=2025-09-21/listings.parquet | Columns: 79 | Price Type: string\n",
      "File: /home/jovyan/work/bronze_layer/listings/city=london/extraction_date=2025-09-14/listings.parquet | Columns: 79 | Price Type: string\n",
      "+-------+\n",
      "|  price|\n",
      "+-------+\n",
      "| $70.00|\n",
      "|$149.00|\n",
      "|$411.00|\n",
      "|   NULL|\n",
      "|$210.00|\n",
      "|$280.00|\n",
      "| $90.00|\n",
      "| $61.00|\n",
      "|$340.00|\n",
      "| $49.00|\n",
      "|   NULL|\n",
      "|$213.00|\n",
      "|   NULL|\n",
      "| $96.00|\n",
      "|   NULL|\n",
      "| $71.00|\n",
      "|   NULL|\n",
      "| $48.00|\n",
      "|   NULL|\n",
      "| $76.00|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import glob\n",
    "\n",
    "path = \"/home/jovyan/work/bronze_layer/listings/**/*.parquet\"\n",
    "files = glob.glob(path, recursive=True)\n",
    "print(files)\n",
    "\n",
    "for f in files:\n",
    "    file_path = os.path.join(path, f)\n",
    "    # Read just the schema of each file individually\n",
    "    temp_df = spark.read.parquet(f\"file://{file_path}\")\n",
    "    col_count = len(temp_df.columns)\n",
    "    price_type = dict(temp_df.dtypes).get('price')\n",
    "    \n",
    "    print(f\"File: {f} | Columns: {col_count} | Price Type: {price_type}\")\n",
    "\n",
    "df_test = spark.read.parquet('file:///home/jovyan/work/bronze_layer/listings/city=london/extraction_date=2025-09-14/listings.parquet')\n",
    "df_test.select(('price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9869c86-1c1f-41fe-b964-e1a9efb4f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from file:///home/jovyan/work/bronze_layer/listings...\n"
     ]
    }
   ],
   "source": [
    "local_path = \"file:///home/jovyan/work/bronze_layer/listings\"\n",
    "\n",
    "print(f\"Reading data from {local_path}...\")\n",
    "# df_listings = spark.read.parquet(local_path).option(\"mergeSchema\", \"true\")\n",
    "df_listings = spark.read \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .parquet(\"file:///home/jovyan/work/bronze_layer/listings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8f6b4e-0ce9-411d-a854-c063d54f7441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+------+---------------+\n",
      "|   id|                name|  price|  city|extraction_date|\n",
      "+-----+--------------------+-------+------+---------------+\n",
      "|13913|Holiday London DB...| $70.00|london|     2025-09-14|\n",
      "|15400|Bright Chelsea  A...|$149.00|london|     2025-09-14|\n",
      "|17402|Very Central Mode...|$411.00|london|     2025-09-14|\n",
      "|24328|Battersea live/wo...|   NULL|london|     2025-09-14|\n",
      "|36274|Bright 1 bedroom ...|$210.00|london|     2025-09-14|\n",
      "|36299|Kew Gardens 3BR h...|$280.00|london|     2025-09-14|\n",
      "|36660|You are GUARANTEE...| $90.00|london|     2025-09-14|\n",
      "|38605|SUNNY ROOM PRIVAT...| $61.00|london|     2025-09-14|\n",
      "|38610|     Short Term Home|$340.00|london|     2025-09-14|\n",
      "|38995|SPACIOUS ROOM IN ...| $49.00|london|     2025-09-14|\n",
      "|39387|Stylish bedsit in...|   NULL|london|     2025-09-14|\n",
      "|41445|2 Double bed apar...|$213.00|london|     2025-09-14|\n",
      "|41509|Room in maisonett...|   NULL|london|     2025-09-14|\n",
      "|41712|Room with a view,...| $96.00|london|     2025-09-14|\n",
      "|41870|Room in relaxed f...|   NULL|london|     2025-09-14|\n",
      "|42010|You Will Save Mon...| $71.00|london|     2025-09-14|\n",
      "|42692|Fabulous flat w g...|   NULL|london|     2025-09-14|\n",
      "|43129|Quiet Comfortable...| $48.00|london|     2025-09-14|\n",
      "|43202|Beautiful 1 bed a...|   NULL|london|     2025-09-14|\n",
      "|45163|  Room with a garden| $76.00|london|     2025-09-14|\n",
      "+-----+--------------------+-------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listings.select(\"id\", \"name\", \"price\", \"city\", \"extraction_date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c442e0b-6741-4fac-b6ca-183f12570c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = df_listings.withColumn('updated_at_utc+0', F.current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bcdc89-3a8c-4349-9f32-93357fe90378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingestion complete. Data stored at: hdfs://namenode:9000/user/hive/warehouse/airbnb.db/bronze/listings\n"
     ]
    }
   ],
   "source": [
    "hdfs_destination = \"hdfs://namenode:9000/user/hive/warehouse/airbnb.db/bronze/listings\"\n",
    "\n",
    "(df_listings.write\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"extraction_date\", \"city\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .save(hdfs_destination))\n",
    "\n",
    "print(f\"✅ Ingestion complete. Data stored at: {hdfs_destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1c47b9-e998-4236-b988-013669bdfd8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Create the Database\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE DATABASE IF NOT EXISTS airbnb_bronze\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 2. Create the Table\u001b[39;00m\n\u001b[1;32m      5\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mCREATE EXTERNAL TABLE IF NOT EXISTS airbnb_bronze.listings (\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    id BIGINT,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124mLOCATION \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/user/hive/warehouse/airbnb.db/bronze/listings\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m'''\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient"
     ]
    }
   ],
   "source": [
    "# 1. Create the Database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS airbnb_bronze\")\n",
    "\n",
    "# 2. Create the Table\n",
    "spark.sql('''\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS airbnb_bronze.listings (\n",
    "    id BIGINT,\n",
    "    listing_url STRING,\n",
    "    scrape_id BIGINT,\n",
    "    last_scraped STRING,\n",
    "    source STRING,\n",
    "    name STRING,\n",
    "    description STRING,\n",
    "    neighborhood_overview STRING,\n",
    "    picture_url STRING,\n",
    "    host_id BIGINT,\n",
    "    host_url STRING,\n",
    "    host_name STRING,\n",
    "    host_since STRING,\n",
    "    host_location STRING,\n",
    "    host_about STRING,\n",
    "    host_response_time STRING,\n",
    "    host_response_rate STRING,\n",
    "    host_acceptance_rate STRING,\n",
    "    host_is_superhost STRING,\n",
    "    host_thumbnail_url STRING,\n",
    "    host_picture_url STRING,\n",
    "    host_neighbourhood STRING,\n",
    "    host_listings_count DOUBLE,\n",
    "    host_total_listings_count DOUBLE,\n",
    "    host_verifications STRING,\n",
    "    host_has_profile_pic STRING,\n",
    "    host_identity_verified STRING,\n",
    "    neighbourhood STRING,\n",
    "    neighbourhood_cleansed STRING,\n",
    "    neighbourhood_group_cleansed DOUBLE,\n",
    "    latitude DOUBLE,\n",
    "    longitude DOUBLE,\n",
    "    property_type STRING,\n",
    "    room_type STRING,\n",
    "    accommodates BIGINT,\n",
    "    bathrooms DOUBLE,\n",
    "    bathrooms_text STRING,\n",
    "    bedrooms DOUBLE,\n",
    "    beds DOUBLE,\n",
    "    amenities STRING,\n",
    "    price STRING,\n",
    "    minimum_nights BIGINT,\n",
    "    maximum_nights BIGINT,\n",
    "    minimum_minimum_nights DOUBLE,\n",
    "    maximum_minimum_nights DOUBLE,\n",
    "    minimum_maximum_nights DOUBLE,\n",
    "    maximum_maximum_nights DOUBLE,\n",
    "    minimum_nights_avg_ntm DOUBLE,\n",
    "    maximum_nights_avg_ntm DOUBLE,\n",
    "    calendar_updated DOUBLE,\n",
    "    has_availability STRING,\n",
    "    availability_30 BIGINT,\n",
    "    availability_60 BIGINT,\n",
    "    availability_90 BIGINT,\n",
    "    availability_365 BIGINT,\n",
    "    calendar_last_scraped STRING,\n",
    "    number_of_reviews BIGINT,\n",
    "    number_of_reviews_ltm BIGINT,\n",
    "    number_of_reviews_l30d BIGINT,\n",
    "    availability_eoy BIGINT,\n",
    "    number_of_reviews_ly BIGINT,\n",
    "    estimated_occupancy_l365d BIGINT,\n",
    "    estimated_revenue_l365d DOUBLE,\n",
    "    first_review STRING,\n",
    "    last_review STRING,\n",
    "    review_scores_rating DOUBLE,\n",
    "    review_scores_accuracy DOUBLE,\n",
    "    review_scores_cleanliness DOUBLE,\n",
    "    review_scores_checkin DOUBLE,\n",
    "    review_scores_communication DOUBLE,\n",
    "    review_scores_location DOUBLE,\n",
    "    review_scores_value DOUBLE,\n",
    "    license STRING,\n",
    "    instant_bookable STRING,\n",
    "    calculated_host_listings_count BIGINT,\n",
    "    calculated_host_listings_count_entire_homes BIGINT,\n",
    "    calculated_host_listings_count_private_rooms BIGINT,\n",
    "    calculated_host_listings_count_shared_rooms BIGINT,\n",
    "    reviews_per_month DOUBLE\n",
    ")\n",
    "-- city and extraction_date move here!\n",
    "PARTITIONED BY (extraction_date DATE, city STRING) \n",
    "STORED AS PARQUET\n",
    "LOCATION '/user/hive/warehouse/airbnb.db/bronze/listings';\n",
    "''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fe5625-370c-4c84-b214-3a6ff0307b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Register the partitions (Crucial!)\n",
    "spark.sql(\"MSCK REPAIR TABLE airbnb_bronze.listings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
