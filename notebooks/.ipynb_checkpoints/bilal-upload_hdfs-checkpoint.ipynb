{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782a99da-241b-4142-bbc9-7d7be9ca5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9c006a-d245-445f-851c-3b52ad98bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HADOOP_USER_NAME\"] = \"root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4e61b5-f2ef-452c-ab5c-5b02111afb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21cf9ab-7928-44e5-9805-59f553f92de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:10:33,502 | INFO | Starting Spark Bronze Ingestion Job\n",
      "2026-01-01 03:10:40,444 | INFO | Spark session initialized\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting Spark Bronze Ingestion Job\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"bronze-spark-upload-hdfs\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "logger.info(\"Spark session initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313398a0-ed40-4419-94bd-7f87cb3bf19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:12:30,918 | INFO | Reading parquet data from file:///home/jovyan/work/bronze_layer/listings\n",
      "2026-01-01 03:12:38,880 | INFO | Loaded 104652 rows\n"
     ]
    }
   ],
   "source": [
    "local_path = \"file:///home/jovyan/work/bronze_layer/listings\"\n",
    "logger.info(f\"Reading parquet data from {local_path}\")\n",
    "\n",
    "df_listings = (\n",
    "    spark.read\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    .parquet(local_path)\n",
    ")\n",
    "\n",
    "row_count = df_listings.count()\n",
    "logger.info(f\"Loaded {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d3cf3a-d040-4d67-960d-d5e49b017061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 05:38:28,513 | INFO | Reading parquet data for Brsitol from file:///home/jovyan/work/bronze_layer/listings/city=bristol\n",
      "2025-12-31 05:38:36,844 | INFO | Loaded 8496 rows\n"
     ]
    }
   ],
   "source": [
    "# local_path = \"file:///home/jovyan/work/bronze_layer/listings/city=bristol\"\n",
    "# logger.info(f\"Reading parquet data for Brsitol from {local_path}\")\n",
    "\n",
    "# bristol_listings = (\n",
    "#     spark.read\n",
    "#     .parquet(local_path)\n",
    "# )\n",
    "\n",
    "# row_count = bristol_listings.count()\n",
    "# logger.info(f\"Loaded {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4c04d4-b60b-43e0-ab7d-4d9b25cd57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|extraction_date|\n",
      "+---------------+\n",
      "|     2025-03-19|\n",
      "|     2025-06-24|\n",
      "|     2025-09-26|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bristol_listings.select(\"extraction_date\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f063ee-64ad-4fbb-93fa-e571666451e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 05:38:41,899 | INFO | Reading parquet data for Edinburgh from file:///home/jovyan/work/bronze_layer/listings/city=edinburgh\n",
      "2025-12-31 05:38:42,756 | INFO | Loaded 16538 rows\n"
     ]
    }
   ],
   "source": [
    "# local_path = \"file:///home/jovyan/work/bronze_layer/listings/city=edinburgh\"\n",
    "# logger.info(f\"Reading parquet data for Edinburgh from {local_path}\")\n",
    "\n",
    "# edinburgh_listings = (\n",
    "#     spark.read\n",
    "#     .parquet(local_path)\n",
    "# )\n",
    "\n",
    "# row_count = edinburgh_listings.count()\n",
    "# logger.info(f\"Loaded {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a720cb-1400-4780-a514-cc25974da466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|extraction_date|\n",
      "+---------------+\n",
      "|     2025-06-15|\n",
      "|     2025-03-08|\n",
      "|     2025-09-21|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# edinburgh_listings.select(\"extraction_date\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46fd6fb-5f72-4227-816f-c924ed1472a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 05:38:45,589 | INFO | Reading parquet data for London from file:///home/jovyan/work/bronze_layer/listings/city=london\n",
      "2025-12-31 05:38:46,663 | INFO | Loaded 288081 rows\n"
     ]
    }
   ],
   "source": [
    "# local_path = \"file:///home/jovyan/work/bronze_layer/listings/city=london\"\n",
    "# logger.info(f\"Reading parquet data for London from {local_path}\")\n",
    "\n",
    "# london_listings = (\n",
    "#     spark.read\n",
    "#     .parquet(local_path)\n",
    "# )\n",
    "\n",
    "# row_count = london_listings.count()\n",
    "# logger.info(f\"Loaded {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265cdf0a-b075-4894-bb29-f96e0cd46793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|extraction_date|\n",
      "+---------------+\n",
      "|     2025-03-04|\n",
      "|     2025-06-10|\n",
      "|     2025-09-14|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# london_listings.select(\"extraction_date\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7d77a9-ef63-4fc3-9824-9100aa28a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bristol columns: 80\n",
      "Edinburgh columns: 80\n",
      "London columns: 80\n"
     ]
    }
   ],
   "source": [
    "# print(\"Bristol columns:\", len(bristol_listings.columns))\n",
    "# print(\"Edinburgh columns:\", len(edinburgh_listings.columns))\n",
    "# print(\"London columns:\", len(london_listings.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1f3225-80f7-435a-ab84-35bd4c25e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bristol_listings = bristol_listings.withColumn(\"city\", lit(\"bristol\"))\n",
    "# edinburgh_listings = edinburgh_listings.withColumn(\"city\", lit(\"edinburgh\"))\n",
    "# london_listings = london_listings.withColumn(\"city\", lit(\"london\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "017f18a2-8a62-4e08-8b0a-0cb806952296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_listings = (\n",
    "#     bristol_listings\n",
    "#     .unionByName(edinburgh_listings)\n",
    "#     .unionByName(london_listings)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec25b34-f108-4fba-8128-395449dfefd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313115"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_listings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ed71f3-e1b4-415d-8af2-4175633487da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     city| count|\n",
      "+---------+------+\n",
      "|  bristol|  8496|\n",
      "|edinburgh| 16538|\n",
      "|   london|288081|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_listings.groupBy(\"city\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d8853e-bfb3-4353-abe7-1d2367b33a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|extraction_date|count|\n",
      "+---------------+-----+\n",
      "|     2025-03-19| 2772|\n",
      "|     2025-06-24| 2879|\n",
      "|     2025-09-26| 2845|\n",
      "|     2025-06-15| 5936|\n",
      "|     2025-03-08| 5666|\n",
      "|     2025-09-21| 4936|\n",
      "|     2025-03-04|94559|\n",
      "|     2025-06-10|96651|\n",
      "|     2025-09-14|96871|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_listings.groupBy(\"extraction_date\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0174219f-9e11-422d-986d-43a4e5415a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:13:06,712 | INFO | Adding updated_at_utc_0 column\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Adding updated_at_utc_0 column\")\n",
    "\n",
    "df_listings = df_listings.withColumn(\n",
    "    \"updated_at_utc_0\",\n",
    "    F.current_timestamp()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50f901e2-a8f9-4f30-8987-98b571782d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- listing_url: string (nullable = true)\n",
      " |-- scrape_id: long (nullable = true)\n",
      " |-- last_scraped: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- neighborhood_overview: string (nullable = true)\n",
      " |-- picture_url: string (nullable = true)\n",
      " |-- host_id: long (nullable = true)\n",
      " |-- host_url: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- host_since: string (nullable = true)\n",
      " |-- host_location: string (nullable = true)\n",
      " |-- host_about: string (nullable = true)\n",
      " |-- host_response_time: string (nullable = true)\n",
      " |-- host_response_rate: string (nullable = true)\n",
      " |-- host_acceptance_rate: string (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_thumbnail_url: string (nullable = true)\n",
      " |-- host_picture_url: string (nullable = true)\n",
      " |-- host_neighbourhood: string (nullable = true)\n",
      " |-- host_listings_count: long (nullable = true)\n",
      " |-- host_total_listings_count: double (nullable = true)\n",
      " |-- host_verifications: string (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- neighbourhood_cleansed: string (nullable = true)\n",
      " |-- neighbourhood_group_cleansed: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: long (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bathrooms_text: string (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- beds: double (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: long (nullable = true)\n",
      " |-- maximum_nights: long (nullable = true)\n",
      " |-- minimum_minimum_nights: long (nullable = true)\n",
      " |-- maximum_minimum_nights: long (nullable = true)\n",
      " |-- minimum_maximum_nights: long (nullable = true)\n",
      " |-- maximum_maximum_nights: long (nullable = true)\n",
      " |-- minimum_nights_avg_ntm: double (nullable = true)\n",
      " |-- maximum_nights_avg_ntm: double (nullable = true)\n",
      " |-- calendar_updated: double (nullable = true)\n",
      " |-- has_availability: string (nullable = true)\n",
      " |-- availability_30: long (nullable = true)\n",
      " |-- availability_60: long (nullable = true)\n",
      " |-- availability_90: long (nullable = true)\n",
      " |-- availability_365: long (nullable = true)\n",
      " |-- calendar_last_scraped: string (nullable = true)\n",
      " |-- number_of_reviews: long (nullable = true)\n",
      " |-- number_of_reviews_ltm: long (nullable = true)\n",
      " |-- number_of_reviews_l30d: long (nullable = true)\n",
      " |-- availability_eoy: long (nullable = true)\n",
      " |-- number_of_reviews_ly: long (nullable = true)\n",
      " |-- estimated_occupancy_l365d: long (nullable = true)\n",
      " |-- estimated_revenue_l365d: double (nullable = true)\n",
      " |-- first_review: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- review_scores_rating: double (nullable = true)\n",
      " |-- review_scores_accuracy: double (nullable = true)\n",
      " |-- review_scores_cleanliness: double (nullable = true)\n",
      " |-- review_scores_checkin: double (nullable = true)\n",
      " |-- review_scores_communication: double (nullable = true)\n",
      " |-- review_scores_location: double (nullable = true)\n",
      " |-- review_scores_value: double (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- calculated_host_listings_count: long (nullable = true)\n",
      " |-- calculated_host_listings_count_entire_homes: long (nullable = true)\n",
      " |-- calculated_host_listings_count_private_rooms: long (nullable = true)\n",
      " |-- calculated_host_listings_count_shared_rooms: long (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      " |-- extraction_date: date (nullable = true)\n",
      " |-- city: string (nullable = false)\n",
      " |-- updated_at_utc_0: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_listings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf91e538-5654-4438-a135-12dff031ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_cast = [\n",
    "#     \"minimum_minimum_nights\",\n",
    "#     \"maximum_minimum_nights\",\n",
    "#     \"minimum_maximum_nights\",\n",
    "#     \"maximum_maximum_nights\",\n",
    "#     \"host_listings_count\"\n",
    "# ]\n",
    "\n",
    "# for c in columns_to_cast:\n",
    "#     df_listings = df_listings.withColumn(c, col(c).cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f325d5c0-900d-4528-b942-df439ad915cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_listings = df_listings.withColumn(\"host_listings_count\", col(\"host_listings_count\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61272e45-fd8a-486f-b425-066241546876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:28:25,456 | INFO | Writing data to HDFS at hdfs://namenode:9000/user/hive/warehouse/airbnb.db/bilal/bronze/listings\n",
      "2026-01-01 03:28:31,187 | INFO | HDFS write completed successfully\n"
     ]
    }
   ],
   "source": [
    "hdfs_destination = \"hdfs://namenode:9000/user/hive/warehouse/airbnb.db/bilal/bronze/listings\"\n",
    "logger.info(f\"Writing data to HDFS at {hdfs_destination}\")\n",
    "\n",
    "(\n",
    "    df_listings.write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"city\", \"extraction_date\")\n",
    "    .format(\"parquet\")\n",
    "    .save(hdfs_destination)\n",
    ")\n",
    "\n",
    "logger.info(\"HDFS write completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e7faf9-d4ce-49c7-8c8a-6ec635afdb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:19:22,776 | INFO | Reading parquet data from file:///home/jovyan/work/bronze_layer/neighbourhoods\n",
      "2026-01-01 03:19:23,290 | INFO | Loaded 178 rows\n"
     ]
    }
   ],
   "source": [
    "local_path = \"file:///home/jovyan/work/bronze_layer/neighbourhoods\"\n",
    "logger.info(f\"Reading parquet data from {local_path}\")\n",
    "\n",
    "df_neighbourhoods = (\n",
    "    spark.read\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    .parquet(local_path)\n",
    ")\n",
    "\n",
    "row_count = df_neighbourhoods.count()\n",
    "logger.info(f\"Loaded {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4dfc09-89e3-48ae-8441-0ed147e2970e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:20:45,941 | INFO | Adding updated_at_utc_0 column\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Adding updated_at_utc_0 column\")\n",
    "\n",
    "df_neighbourhoods = df_neighbourhoods.withColumn(\n",
    "    \"updated_at_utc_0\",\n",
    "    F.current_timestamp()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fbf458-af2a-4157-8ac2-c0817e8aa71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 03:29:49,472 | INFO | Writing data to HDFS at hdfs://namenode:9000/user/hive/warehouse/airbnb.db/bilal/bronze/neighbourhoods\n",
      "2026-01-01 03:29:50,418 | INFO | HDFS write completed successfully\n"
     ]
    }
   ],
   "source": [
    "hdfs_destination = \"hdfs://namenode:9000/user/hive/warehouse/airbnb.db/bilal/bronze/neighbourhoods\"\n",
    "logger.info(f\"Writing data to HDFS at {hdfs_destination}\")\n",
    "\n",
    "(\n",
    "    df_neighbourhoods.write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"city\")\n",
    "    .format(\"parquet\")\n",
    "    .save(hdfs_destination)\n",
    ")\n",
    "\n",
    "logger.info(\"HDFS write completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b995e9-c8f0-4fe2-a560-40615d9e72a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 04:33:23,896 | INFO | Ensuring Hive database exists\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsuring Hive database exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE DATABASE IF NOT EXISTS airbnb_bilal_bronze\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient"
     ]
    }
   ],
   "source": [
    "logger.info(\"Ensuring Hive database exists\")\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS airbnb_bilal_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6621cd-ce88-486d-b547-830f27258e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
